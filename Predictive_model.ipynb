{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ZeroToH3ro/Predictive-Model-Advance/blob/main/Predictive_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nDqgslP2awmd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as FDA\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fpPnKa0ec5JD"
   },
   "outputs": [],
   "source": [
    "def sequence_to_features(seq, seq_type='dna', daas=None):\n",
    "    \"\"\"\n",
    "    seq_type='dna' will apply the DNA mapping,\n",
    "    seq_type='aa'  will apply the amino acid mapping.\n",
    "    daas is 1 if the medicine is used, else 0.\n",
    "    \"\"\"\n",
    "    if seq is None or (isinstance(seq, float) and np.isnan(seq)):\n",
    "        seq = ''\n",
    "    else:\n",
    "        seq = str(seq)\n",
    "\n",
    "    # DNA base mapping\n",
    "    base_dict = {\n",
    "        'A': 1, 'C': 2, 'G': 3, 'T': 4,\n",
    "        'N': 0, '-': 0,\n",
    "        'R': 5, 'Y': 6, 'M': 7, 'K': 8,\n",
    "        'S': 9, 'W': 10, 'H': 11, 'B': 12,\n",
    "        'V': 13, 'D': 14\n",
    "    }\n",
    "\n",
    "    # Amino acid mapping\n",
    "    aa_dict = {\n",
    "        'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5,\n",
    "        'Q': 6, 'E': 7, 'G': 8, 'H': 9, 'I': 10,\n",
    "        'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15,\n",
    "        'S': 16, 'T': 17, 'W': 18, 'Y': 19, 'V': 20,\n",
    "        '-': 0, 'X': 0\n",
    "    }\n",
    "\n",
    "    features = []\n",
    "    if seq_type == 'dna':\n",
    "        features = [base_dict.get(base, 0) for base in seq]\n",
    "    elif seq_type == 'aa':\n",
    "        features = [aa_dict.get(aa, 0) for aa in seq]\n",
    "    else:\n",
    "        raise ValueError(\"seq_type must be either 'dna' or 'aa'\")\n",
    "\n",
    "    # Include DAAS (medicine) as a binary feature if provided\n",
    "    if daas is not None:\n",
    "        features.append(int(daas))  # 1 if True, else 0\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmliD8lm6TWy"
   },
   "outputs": [],
   "source": [
    "def prepare_data_nucleotide(data_path):\n",
    "    # Load dataset (CSV or Excel)\n",
    "    if str(data_path).lower().endswith('.csv'):\n",
    "        data = pd.read_csv(data_path)\n",
    "        if all((str(col).strip() == '' or str(col).startswith('Unnamed')) for col in data.columns):\n",
    "            data = pd.read_csv(data_path, skiprows=2)\n",
    "    else:\n",
    "        data = pd.read_excel(data_path)\n",
    "\n",
    "    # Select only the nucleotide columns you specified\n",
    "    nucleotide_columns = ['NS3_Nu', 'NS5A_Nu', 'NS5B_Nu']\n",
    "    alt_nucleotide_columns = ['NS3 Nu', 'NS5A Nu', 'NS5B Nu']\n",
    "\n",
    "    if all(col in data.columns for col in nucleotide_columns):\n",
    "        selected_columns = nucleotide_columns\n",
    "\n",
    "    # Convert nucleotide sequences to numerical features\n",
    "    X = data[selected_columns].applymap(lambda seq: sequence_to_features(seq, seq_type='dna')).values.tolist()\n",
    "\n",
    "    # Pad the sequences to make them the same length\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    # This calculates the maximum sequence length\n",
    "    max_seq_len = max(len(seq) for row in X for seq in row)\n",
    "    X = [[pad_sequences([seq], maxlen=max_seq_len, padding='post', value=0)[0] for seq in row] for row in X]\n",
    "\n",
    "    X = np.array(X)  # Convert the list of lists to a NumPy array\n",
    "\n",
    "    # Target vector y from \"Respond\"\n",
    "    response_map = {'Yes': 1, 'No': 0, 'SVR': 1, 'Non SVR': 0, 'Non-SVR': 0}\n",
    "    response_series = data['Respond'].astype(str).str.strip()\n",
    "    y = response_series.map(response_map)\n",
    "    if y.isna().any():\n",
    "        bad_values = sorted(response_series[y.isna()].unique())\n",
    "        raise ValueError(f\"Unmapped Respond values: {bad_values}\")\n",
    "    y = y.values\n",
    "\n",
    "    # Add a check for unique values in y\n",
    "    unique_classes = np.unique(y)\n",
    "    if len(unique_classes) < 2:\n",
    "        raise ValueError(f\"Target variable 'Respond' has only {len(unique_classes)} unique class(es): {unique_classes}. \"\n",
    "                         f\"At least two classes are needed for classification.\")\n",
    "\n",
    "    return X, y, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCxXur2E6fPB"
   },
   "outputs": [],
   "source": [
    "def prepare_data_amino(data_path):\n",
    "    # Load dataset (CSV or Excel)\n",
    "    if str(data_path).lower().endswith('.csv'):\n",
    "        data = pd.read_csv(data_path)\n",
    "        if all((str(col).strip() == '' or str(col).startswith('Unnamed')) for col in data.columns):\n",
    "            data = pd.read_csv(data_path, skiprows=2)\n",
    "    else:\n",
    "        data = pd.read_excel(data_path)\n",
    "\n",
    "    # Select only the amino acid columns you specified\n",
    "    amino_columns = ['NS3_Aa', 'NS5A_Aa', 'NS5B_Aa']\n",
    "\n",
    "    if all(col in data.columns for col in amino_columns):\n",
    "        selected_columns = amino_columns\n",
    "\n",
    "    # Convert amino acid sequences to numerical features\n",
    "    X = data[selected_columns].applymap(lambda seq: sequence_to_features(seq, seq_type='aa')).values.tolist()\n",
    "\n",
    "    # Pad the sequences to make them the same length\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    # This calculates the maximum sequence length for amino acid sequences\n",
    "    max_seq_len = max(len(seq) for row in X for seq in row)\n",
    "    X = [[pad_sequences([seq], maxlen=max_seq_len, padding='post', value=0)[0] for seq in row] for row in X]\n",
    "    X = np.array(X)  # Convert the list of lists to a NumPy array\n",
    "    \n",
    "    # Target vector y from \"Respond\"\n",
    "    response_map = {'Yes': 1, 'No': 0, 'SVR': 1, 'Non SVR': 0, 'Non-SVR': 0}\n",
    "    response_series = data['Respond'].astype(str).str.strip()\n",
    "    y = response_series.map(response_map)\n",
    "    if y.isna().any():\n",
    "        bad_values = sorted(response_series[y.isna()].unique())\n",
    "        raise ValueError(f\"Unmapped Respond values: {bad_values}\")\n",
    "    y = y.values\n",
    "\n",
    "    # Add a check for unique values in y\n",
    "    unique_classes = np.unique(y)\n",
    "    if len(unique_classes) < 2:\n",
    "        raise ValueError(f\"Target variable 'Respond' has only {len(unique_classes)} unique class(es): {unique_classes}. \"\n",
    "                        f\"At least two classes are needed for classification.\")\n",
    "\n",
    "    return X, y, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Io7m-Lc7IpoP"
   },
   "outputs": [],
   "source": [
    "def plot_model_comparison(results):\n",
    "    \"\"\"\n",
    "    Create visualizations comparing model performance\n",
    "    \"\"\"\n",
    "    # Accuracy comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    accuracies = {name: res['accuracy'] for name, res in results.items()}\n",
    "    plt.bar(accuracies.keys(), accuracies.values())\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ROC curves\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.rcParams['lines.linewidth'] = 3.5  # Increase base line width\n",
    "    plt.rcParams['lines.markersize'] = 10  # Increase marker size if any\n",
    "    plt.rcParams['lines.markeredgewidth'] = 2.5  # Increase marker edge width\n",
    "\n",
    "    for name, res in results.items():\n",
    "        # Get the stored fpr, tpr values directly\n",
    "        fpr = res['roc_curve'][0]  # First element is fpr\n",
    "        tpr = res['roc_curve'][1]  # Second element is tpr\n",
    "        auc_score = res['auc']     # Get the pre-calculated AUC score\n",
    "\n",
    "        # Increased linewidth and added solid_capstyle for bolder lines\n",
    "        plt.plot(fpr, tpr,\n",
    "                label=f'{name} (AUC = {auc_score:.2f})',\n",
    "                linewidth=4.0,\n",
    "                solid_capstyle='round',\n",
    "                solid_joinstyle='round')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--',\n",
    "             linewidth=2.5,\n",
    "             dashes=(5, 5),\n",
    "             solid_capstyle='round')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves for Different Models')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "RnuaUd-nuzNj"
   },
   "outputs": [],
   "source": [
    "def optimize_models(X_train_scaled, y_train):\n",
    "    \"\"\"\n",
    "    Optimize hyperparameters for all models using GridSearchCV\n",
    "    \"\"\"\n",
    "    optimized_models = {}\n",
    "\n",
    "    # SVM optimization\n",
    "    svm_params = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'linear', 'poly'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    svm = GridSearchCV(SVC(probability=True, random_state=42), svm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Neural Network optimization\n",
    "    nn_params = {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "        'max_iter': [2000]\n",
    "    }\n",
    "    nn = GridSearchCV(MLPClassifier(random_state=42), nn_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # KNN optimization\n",
    "    knn_params = {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
    "    }\n",
    "    knn = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Logistic Regression optimization\n",
    "    lr_params = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'class_weight': ['balanced', None]\n",
    "    }\n",
    "    lr = GridSearchCV(LogisticRegression(random_state=42, max_iter=2000), lr_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Random Forest optimization\n",
    "    rf_params = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'class_weight': ['balanced', 'balanced_subsample', None]\n",
    "    }\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # FDA optimization\n",
    "    fda_params = {\n",
    "        'solver': ['svd', 'lsqr', 'eigen'],\n",
    "        'shrinkage': [None, 'auto'],\n",
    "        'store_covariance': [True, False]\n",
    "    }\n",
    "    fda = LinearDiscriminantAnalysis()\n",
    "\n",
    "    # GBM optimization\n",
    "    gbm_params = {\n",
    "\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    gbm = GridSearchCV(GradientBoostingClassifier(random_state=42), gbm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Decision Tree optimization\n",
    "    dt_params = {\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "    dt = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Naive Bayes optimization\n",
    "    nb = GaussianNB()\n",
    "\n",
    "     # Voting Classifier\n",
    "    estimators = [('lr', LogisticRegression(random_state=42, max_iter=2000)),\n",
    "                  ('svm', SVC(probability=True, random_state=42)),\n",
    "                  ('rf', RandomForestClassifier(random_state=42))]\n",
    "    voting_clf = VotingClassifier(estimators=estimators, voting='soft') #'soft' for probabilistic voting\n",
    "\n",
    "    # Stacking Classifier\n",
    "    # Ensure lr, svm, and rf are fitted before accessing best_estimator_\n",
    "    lr.fit(X_train_scaled, y_train)  # Fit lr\n",
    "    svm.fit(X_train_scaled, y_train) # Fit svm\n",
    "    rf.fit(X_train_scaled, y_train)  # Fit rf\n",
    "\n",
    "    estimators = [('lr', lr.best_estimator_), ('svm', svm.best_estimator_), ('rf', rf.best_estimator_)]\n",
    "    stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "    models = {\n",
    "        'SVM': svm,\n",
    "        'Neural Network': nn,\n",
    "        'KNN': knn,\n",
    "        'Logistic Regression': lr,\n",
    "        'Random Forest': rf,\n",
    "        'FDA': fda,\n",
    "        'GBM': gbm,\n",
    "        'Decision Tree': dt,\n",
    "        'Naive Bayes': nb,\n",
    "        'Voting Classifier': voting_clf,\n",
    "        'Stacking Classifier': stacking_clf\n",
    "    }\n",
    "\n",
    "    # Fit all models\n",
    "    for name, model in models.items():\n",
    "        print(f\"Optimizing {name}...\")\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        if hasattr(model, 'best_estimator_'):\n",
    "            optimized_models[name] = model.best_estimator_\n",
    "            print(f\"Best parameters for {name}: {model.best_params_}\")\n",
    "            print(f\"Best cross-validation score: {model.best_score_:.4f}\\n\")\n",
    "        else:\n",
    "            optimized_models[name] = model\n",
    "            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "            print(f\"Cross-validation scores for {name}: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\\n\")\n",
    "\n",
    "    return optimized_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cp6Pcw93dJZw",
    "outputId": "a5c16113-a478-444a-9dfa-15f1a4de27e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except Exception:\n",
    "    pass\n",
    "def train_and_evaluate_models(X, y, label='', save_path=None, original_data=None):\n",
    "    if save_path is None:\n",
    "        save_path = os.path.join(os.getcwd(), 'ml_results')\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    print(\"Data of label: \", label)\n",
    "\n",
    "    # Split data with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "    # Get indices for train and test sets before using them\n",
    "    indices = np.arange(len(y))\n",
    "    _, _, _, indices_test = train_test_split(X, indices, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "    split_info = pd.DataFrame()\n",
    "\n",
    "    if original_data is not None:\n",
    "        # Get indices for train and test sets\n",
    "        indices = np.arange(len(y))\n",
    "        _, _, _, indices_test = train_test_split(X, indices, test_size=0.4, random_state=42, stratify=y)\n",
    "\n",
    "        indices_train = np.array([i for i in range(len(y)) if i not in indices_test])\n",
    "\n",
    "        # Create DataFrames for training and test sets\n",
    "        train_data = original_data.iloc[indices_train].copy()\n",
    "        test_data = original_data.iloc[indices_test].copy()\n",
    "\n",
    "        # Add dataset column\n",
    "        train_data['Dataset'] = 'Training'\n",
    "        test_data['Dataset'] = 'Test'\n",
    "\n",
    "        # Combine and export\n",
    "        split_info = pd.concat([train_data, test_data], ignore_index=True)\n",
    "        split_info.to_excel(os.path.join(save_path, f'sequence_split_info_{label}.xlsx'), index=False)\n",
    "\n",
    "        print(\"\\nData Split Summary:\")\n",
    "        print(f\"Total sequences: {len(original_data)}\")\n",
    "        print(f\"Training sequences: {len(train_data)}\")\n",
    "        print(f\"Test sequences: {len(test_data)}\")\n",
    "        print(f\"\\nTraining set label distribution:\")\n",
    "        print(pd.Series(y_train).value_counts())\n",
    "        print(f\"\\nTest set label distribution:\")\n",
    "        print(pd.Series(y_test).value_counts())\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))  # Reshape to 2D before scaling\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))  # Reshape to 2D before scaling\n",
    "\n",
    "    # Create test results DataFrame\n",
    "    test_results = pd.DataFrame()\n",
    "    test_results['True_Label'] = y_test\n",
    "\n",
    "    # Get the sequences for test results based on label\n",
    "    if original_data is not None:\n",
    "        if label == 'Nucleotide':\n",
    "            nu_cols = ['NS3_Nu', 'NS5A_Nu', 'NS5B_Nu']\n",
    "            if not all(col in original_data.columns for col in nu_cols):\n",
    "                nu_cols = ['NS3 Nu', 'NS5A Nu', 'NS5B Nu']\n",
    "            test_results['Sequence'] = original_data.iloc[indices_test][nu_cols].apply(lambda row: ''.join(row.values.astype(str)), axis=1).values\n",
    "        elif label == 'Amino_Acid':\n",
    "            aa_cols = ['NS3_Aa', 'NS5A_Aa', 'NS5B_Aa']\n",
    "            if not all(col in original_data.columns for col in aa_cols):\n",
    "                aa_cols = ['NS3 aa', 'NS5A aa', 'NS5B aa']\n",
    "            test_results['Sequence'] = original_data.iloc[indices_test][aa_cols].apply(lambda row: ''.join(row.values.astype(str)), axis=1).values\n",
    "        test_results['Accession Number'] = original_data.iloc[indices_test]['Accession number'].values\n",
    "\n",
    "    # Get optimized models\n",
    "    models = optimize_models(X_train_scaled, y_train)\n",
    "\n",
    "    # Store metrics for all models\n",
    "    metrics_data = []\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        # Train and predict\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "        # Add predictions to test_results DataFrame\n",
    "        test_results[f'{name}_Predicted'] = y_pred\n",
    "        test_results[f'{name}_Probability'] = y_pred_proba\n",
    "        test_results[f'{name}_Correct'] = (y_pred == y_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_data.append({\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1_Score': f1,\n",
    "            'AUC_Score': auc_score\n",
    "        })\n",
    "\n",
    "        # Store results for plotting\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "            'roc_curve': roc_curve(y_test, y_pred_proba),\n",
    "            'auc': auc_score\n",
    "        }\n",
    "\n",
    "        print(f\"\\nResults for {name}:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "    # Export results\n",
    "    print(\"\\nExporting results...\")\n",
    "\n",
    "    # Export detailed test results\n",
    "    test_results.to_excel(os.path.join(save_path, f'detailed_results_{label}.xlsx'), index=False)\n",
    "\n",
    "    # Export metrics summary\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_df.to_excel(os.path.join(save_path, f'model_metrics_{label}.xlsx'), index=False)\n",
    "\n",
    "    print(\"Results export complete\")\n",
    "\n",
    "    # Plot comparisons\n",
    "    plot_model_comparison(results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0fqcBcjYdZD0",
    "outputId": "f27850f1-c3b7-4880-d9c9-91c7d788e6ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yz/lp8h6q9s1mq3w3hrc197vzhc0000gn/T/ipykernel_38811/990093259.py:24: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X = data[selected_columns].applymap(lambda seq: sequence_to_features(seq, seq_type='dna')).values.tolist()\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_training_162_model.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 1) Prepare Nucleotide-based dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_nu, y_nu, original_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data_nucleotide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m results_nu \u001b[38;5;241m=\u001b[39m train_and_evaluate_models(X_nu, y_nu, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNucleotide\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                          save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs/Experiment_Nu\u001b[39m\u001b[38;5;124m'\u001b[39m, original_data\u001b[38;5;241m=\u001b[39moriginal_data)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 2) Prepare Amino_Acid-based dataset\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m, in \u001b[0;36mprepare_data_nucleotide\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Pad the sequences to make them the same length\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# This calculates the maximum sequence length\u001b[39;00m\n\u001b[1;32m     28\u001b[0m max_seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m row)\n\u001b[0;32m---> 29\u001b[0m X \u001b[38;5;241m=\u001b[39m [[pad_sequences([seq], maxlen\u001b[38;5;241m=\u001b[39mmax_seq_len, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[1;32m     31\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)  \u001b[38;5;66;03m# Convert the list of lists to a NumPy array\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Target vector y from \"Respond\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Pad the sequences to make them the same length\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# This calculates the maximum sequence length\u001b[39;00m\n\u001b[1;32m     28\u001b[0m max_seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m row)\n\u001b[0;32m---> 29\u001b[0m X \u001b[38;5;241m=\u001b[39m [[pad_sequences([seq], maxlen\u001b[38;5;241m=\u001b[39mmax_seq_len, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[1;32m     31\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)  \u001b[38;5;66;03m# Convert the list of lists to a NumPy array\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Target vector y from \"Respond\"\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Pad the sequences to make them the same length\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# This calculates the maximum sequence length\u001b[39;00m\n\u001b[1;32m     28\u001b[0m max_seq_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m row)\n\u001b[0;32m---> 29\u001b[0m X \u001b[38;5;241m=\u001b[39m [[\u001b[43mpad_sequences\u001b[49m([seq], maxlen\u001b[38;5;241m=\u001b[39mmax_seq_len, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[1;32m     31\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)  \u001b[38;5;66;03m# Convert the list of lists to a NumPy array\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Target vector y from \"Respond\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "data_path = \"data_training_162_model.csv\"\n",
    "\n",
    "# 1) Prepare Nucleotide-based dataset\n",
    "X_nu, y_nu, original_data = prepare_data_nucleotide(data_path)\n",
    "results_nu = train_and_evaluate_models(X_nu, y_nu, label='Nucleotide',\n",
    "                         save_path='outputs/Experiment_Nu', original_data=original_data)\n",
    "\n",
    "# 2) Prepare Amino_Acid-based dataset\n",
    "X_aa, y_aa, original_data = prepare_data_amino(data_path)\n",
    "results_aa = train_and_evaluate_models(X_aa, y_aa, label='Amino_Acid',\n",
    "                         save_path='/content/drive/MyDrive/ML_Results/Experiment_Axit', original_data=original_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJB3hEOa8ghCUyiT3iRc18",
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "1ln2U64ruT1jzf7nIerbs1_saVD6H83Fe",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
